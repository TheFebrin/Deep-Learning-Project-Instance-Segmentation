{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AytANUXTvx6E"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIG9ZKHbpflI",
    "outputId": "ca3f7ed8-9640-4b1a-e2d9-5fcce31c676b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the train, valid, and test datasets in the COCO format saved in JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQXba-HnpfnO"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/My Drive/pets-train-coco-format.json\" pets-train-coco-format.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JsVSJ7Bpfpy"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/My Drive/pets-test-coco-format.json\" pets-test-coco-format.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the checkpoint from which the training will be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGbEahx03sKV",
    "outputId": "9b039dca-2bd9-41e7-accf-afcc54d5b15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-12 08:43:34--  https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
      "Resolving open-mmlab.s3.ap-northeast-2.amazonaws.com (open-mmlab.s3.ap-northeast-2.amazonaws.com)... 52.219.58.3\n",
      "Connecting to open-mmlab.s3.ap-northeast-2.amazonaws.com (open-mmlab.s3.ap-northeast-2.amazonaws.com)|52.219.58.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 177867103 (170M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth’\n",
      "\n",
      "checkpoints/mask_rc 100%[===================>] 169.63M  15.4MB/s    in 12s     \n",
      "\n",
      "2021-04-12 08:43:47 (14.3 MB/s) - ‘checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth’ saved [177867103/177867103]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
    "      -O checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhYJ-LqZ3u2O"
   },
   "outputs": [],
   "source": [
    "checkpoint = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use CometML we need to know where the Hook is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hv9j7lbk4tXk",
    "outputId": "3fae88aa-0b78-4f33-b569-a1c0cf7df5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mmdet/core/utils/comet_logger_hook.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mmdet/core/utils/comet_logger_hook.py\n",
    "from mmcv.runner import HOOKS, master_only\n",
    "from mmcv.runner.hooks import LoggerHook\n",
    "\n",
    "\n",
    "@HOOKS.register_module()\n",
    "class CometMLLoggerHook(LoggerHook):\n",
    "\n",
    "    def __init__(self,\n",
    "                 project_name=None,\n",
    "                 hyper_params=None,\n",
    "                 import_comet=True,\n",
    "                 interval=10,\n",
    "                 ignore_last=True,\n",
    "                 reset_flag=True,\n",
    "                 by_epoch=True,\n",
    "                 api_key=None):\n",
    "        \"\"\"Class to log metrics to Comet ML.\n",
    "        It requires `comet_ml` to be installed.\n",
    "        Args:\n",
    "            project_name (str, optional):\n",
    "                Send your experiment to a specific project. \n",
    "                Otherwise will be sent to Uncategorized Experiments. \n",
    "                If project name does not already exists Comet.ml will create \n",
    "                a new project.\n",
    "            hyper_params (dict, optional): Logs a dictionary \n",
    "                (or dictionary-like object) of multiple parameters.\n",
    "            import_comet (bool optional): Whether to import comet_ml before run.\n",
    "                WARNING: Comet ML have to be imported before sklearn and torch,\n",
    "                or COMET_DISABLE_AUTO_LOGGING have to be set in the environment.\n",
    "            interval (int): Logging interval (every k iterations).\n",
    "            ignore_last (bool): Ignore the log of last iterations in each epoch\n",
    "                if less than `interval`.\n",
    "            reset_flag (bool): Whether to clear the output buffer after logging\n",
    "            by_epoch (bool): Whether EpochBasedRunner is used.\n",
    "        \"\"\"\n",
    "        super(CometMLLoggerHook, self).__init__(interval, ignore_last,\n",
    "                                                reset_flag, by_epoch)\n",
    "        self._import_comet = import_comet\n",
    "        if import_comet:\n",
    "            self.import_comet()\n",
    "        self.project_name = project_name\n",
    "        self.hyper_params = hyper_params\n",
    "        self._api_key = api_key\n",
    "\n",
    "    def import_comet(self):\n",
    "        try:\n",
    "            import comet_ml\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                'Please run \"pip install comet_ml\" to install Comet ML')\n",
    "        self.comet_ml = comet_ml\n",
    "\n",
    "    @master_only\n",
    "    def before_run(self, runner):\n",
    "        if self._import_comet:\n",
    "            self.experiment = self.comet_ml.Experiment(\n",
    "                api_key=self._api_key,\n",
    "                project_name=self.project_name,\n",
    "            )\n",
    "        else:\n",
    "            self.experiment = comet_ml.Experiment(\n",
    "                api_key=self._api_key,\n",
    "                project_name=self.project_name,\n",
    "            )\n",
    "        if self.hyper_params is not None:\n",
    "            self.experiment.log_parameters(self.hyper_params)\n",
    "\n",
    "    @master_only\n",
    "    def log(self, runner):\n",
    "        tags = self.get_loggable_tags(runner, allow_text=True)\n",
    "        for tag, val in tags.items():\n",
    "            self.experiment.log_metric(name=tag,\n",
    "                                       value=val,\n",
    "                                       step=self.get_iter(runner),\n",
    "                                       epoch=self.get_epoch(runner))\n",
    "\n",
    "    @master_only\n",
    "    def after_run(self, runner):\n",
    "        self.experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to create a config is to modify an existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AhwTfb3rF_x"
   },
   "outputs": [],
   "source": [
    "_base_ = './configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLWzTAxarGCs"
   },
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(_base_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yeiwl0uk8fS8"
   },
   "outputs": [],
   "source": [
    "classes = (\n",
    "    'Abyssinian',\n",
    "    'american_bulldog',\n",
    "    'american_pit_bull_terrier',\n",
    "    'basset_hound',\n",
    "    'beagle',\n",
    "    'Bengal',\n",
    "    'Birman',\n",
    "    'Bombay',\n",
    "    'boxer',\n",
    "    'British_Shorthair',\n",
    "    'chihuahua',\n",
    "    'Egyptian_Mau',\n",
    "    'english_cocker_spaniel',\n",
    "    'english_setter',\n",
    "    'german_shorthaired',\n",
    "    'great_pyrenees',\n",
    "    'havanese',\n",
    "    'japanese_chin',\n",
    "    'keeshond',\n",
    "    'leonberger',\n",
    "    'Maine_Coon',\n",
    "    'miniature_pinscher',\n",
    "    'newfoundland',\n",
    "    'Persian',\n",
    "    'pomeranian',\n",
    "    'pug',\n",
    "    'Ragdoll',\n",
    "    'Russian_Blue',\n",
    "    'saint_bernard',\n",
    "    'samoyed',\n",
    "    'scottish_terrier',\n",
    "    'shiba_inu',\n",
    "    'Siamese',\n",
    "    'Sphynx',\n",
    "    'staffordshire_bull_terrier',\n",
    "    'wheaten_terrier',\n",
    "    'yorkshire_terrier',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vLj2e048QeA"
   },
   "outputs": [],
   "source": [
    "# Changing number of classes\n",
    "cfg.model.roi_head.bbox_head.num_classes = len(classes)\n",
    "cfg.model.roi_head.mask_head.num_classes = len(classes)\n",
    "\n",
    "# Folder in which train images are store.\n",
    "cfg.data.train.img_prefix = 'images/'\n",
    "cfg.data.train.classes = classes\n",
    "# Path to train dataset in the COCO format.\n",
    "cfg.data.train.ann_file = 'pets-train-coco-format.json'\n",
    "\n",
    "# Folder in which val images are store.\n",
    "cfg.data.val.img_prefix = 'images/'\n",
    "cfg.data.val.classes = classes\n",
    "# Path to val dataset in the COCO format.\n",
    "cfg.data.val.ann_file = 'pets-test-coco-format.json'\n",
    "\n",
    "# Folder in which test images are store.\n",
    "cfg.data.test.img_prefix = 'images/'\n",
    "cfg.data.test.classes = classes\n",
    "# Path to test dataset in the COCO format.\n",
    "cfg.data.test.ann_file = 'pets-test-coco-format.json'\n",
    "\n",
    "# Path to the checkpoint from which training will be started.\n",
    "cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "\n",
    "# Logging interval\n",
    "cfg.log_config.interval = 25\n",
    "\n",
    "# Setting logging hooks, ee can set specific params, for example:\n",
    "#          dict(type='CometMLLoggerHook', api_key='your_api_key')\n",
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='CometMLLoggerHook')\n",
    "]\n",
    "\n",
    "# Path to CometML Hook file.\n",
    "cfg.custom_imports = dict(imports=['mmdet.core.utils.comet_logger_hook'],\n",
    "                          allow_failed_imports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEb9CeIirGFf",
    "outputId": "00664487-27fe-41bb-8c55-392e8bef8392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    pretrained='open-mmlab://detectron2/resnet50_caffe',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=37,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=37,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=True,\n",
      "        poly2mask=False),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
      "                   (1333, 768), (1333, 800)],\n",
      "        multiscale_mode='value',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='pets-train-37-coco-format.json',\n",
      "        img_prefix='images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                poly2mask=False),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
      "                           (1333, 768), (1333, 800)],\n",
      "                multiscale_mode='value',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ],\n",
      "        classes=('Abyssinian', 'american_bulldog', 'american_pit_bull_terrier',\n",
      "                 'basset_hound', 'beagle', 'Bengal', 'Birman', 'Bombay',\n",
      "                 'boxer', 'British_Shorthair', 'chihuahua', 'Egyptian_Mau',\n",
      "                 'english_cocker_spaniel', 'english_setter',\n",
      "                 'german_shorthaired', 'great_pyrenees', 'havanese',\n",
      "                 'japanese_chin', 'keeshond', 'leonberger', 'Maine_Coon',\n",
      "                 'miniature_pinscher', 'newfoundland', 'Persian', 'pomeranian',\n",
      "                 'pug', 'Ragdoll', 'Russian_Blue', 'saint_bernard', 'samoyed',\n",
      "                 'scottish_terrier', 'shiba_inu', 'Siamese', 'Sphynx',\n",
      "                 'staffordshire_bull_terrier', 'wheaten_terrier',\n",
      "                 'yorkshire_terrier')),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='pets-test-37-coco-format.json',\n",
      "        img_prefix='images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('Abyssinian', 'american_bulldog', 'american_pit_bull_terrier',\n",
      "                 'basset_hound', 'beagle', 'Bengal', 'Birman', 'Bombay',\n",
      "                 'boxer', 'British_Shorthair', 'chihuahua', 'Egyptian_Mau',\n",
      "                 'english_cocker_spaniel', 'english_setter',\n",
      "                 'german_shorthaired', 'great_pyrenees', 'havanese',\n",
      "                 'japanese_chin', 'keeshond', 'leonberger', 'Maine_Coon',\n",
      "                 'miniature_pinscher', 'newfoundland', 'Persian', 'pomeranian',\n",
      "                 'pug', 'Ragdoll', 'Russian_Blue', 'saint_bernard', 'samoyed',\n",
      "                 'scottish_terrier', 'shiba_inu', 'Siamese', 'Sphynx',\n",
      "                 'staffordshire_bull_terrier', 'wheaten_terrier',\n",
      "                 'yorkshire_terrier')),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='pets-test-37-coco-format.json',\n",
      "        img_prefix='images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=('Abyssinian', 'american_bulldog', 'american_pit_bull_terrier',\n",
      "                 'basset_hound', 'beagle', 'Bengal', 'Birman', 'Bombay',\n",
      "                 'boxer', 'British_Shorthair', 'chihuahua', 'Egyptian_Mau',\n",
      "                 'english_cocker_spaniel', 'english_setter',\n",
      "                 'german_shorthaired', 'great_pyrenees', 'havanese',\n",
      "                 'japanese_chin', 'keeshond', 'leonberger', 'Maine_Coon',\n",
      "                 'miniature_pinscher', 'newfoundland', 'Persian', 'pomeranian',\n",
      "                 'pug', 'Ragdoll', 'Russian_Blue', 'saint_bernard', 'samoyed',\n",
      "                 'scottish_terrier', 'shiba_inu', 'Siamese', 'Sphynx',\n",
      "                 'staffordshire_bull_terrier', 'wheaten_terrier',\n",
      "                 'yorkshire_terrier')))\n",
      "evaluation = dict(metric=['bbox', 'segm'])\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(\n",
      "    interval=1,\n",
      "    hooks=[dict(type='TextLoggerHook'),\n",
      "           dict(type='CometMLLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "custom_imports = dict(\n",
      "    imports=['mmdet.core.utils.comet_logger_hook'], allow_failed_imports=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to save the config file in the .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JqaGAODrGIw"
   },
   "outputs": [],
   "source": [
    "cfg.dump('mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_pets.py')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MMdet, pets dataset, round 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
